% Chapter Template

\chapter{Conclusion and Further Investigation} % Main chapter title

\label{Chapter7} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Conclusion}
We have seen different methods for pricing equity options within the Black-Scholes world. We have specifically focused on the European Call, Exotic European, American Put and American Put minimum on two stocks. The closed form solutions and the classical binomial lattice model and LSM were provided for investigating the potential of using deep learning in option pricing theory. \\

The numerical investigation showed that MLPs I and MLPs II pricing methods were inferior in accuracy for univariate and bivariate contingent claims, but the MLPs II had an enhanced speed compare to the classical methods after training. The results for the MLPs I were somewhat discouraging, but the theory tells us we can improve our training algorithm to perform on the same level as LSM. The CRR model was extended to the BEG method with two underlying stocks, which we saw gave a good approximation for European bivariate claims. The BEG method has its limitations in terms of pricing a basket option with many underlying stocks, which can be solved with LSM or MLPs I.\\

To sum up the MLPs I needs hyperparameter tuning, but the underlying theory and idea gives hope for finding a better model for high dimensional data than the classical LSM. The BEG has its limitation in high dimensions, hence LSM is preferred for higher dimensions. The MLPs II showed better performance than for polynomial regression at supervised learning. Furthermore the MLPs II can be beneficial in terms of computational speed, but has lower precision for univariate contingent claims than the LSM compared to our CRR benchmark price.\\


%-----------------------------------
%	SECTION 2
%-----------------------------------
\section{Further Investigation}
The code library is written in python, which could be optimized in terms of computational speed with e.g. Julia or C++. The advantage with python is the libraries for machine learning and specially deep learning. The code could also be more generalized not only to handle specific option contracts by using the object oriented programming paradigm instead of procedural programming approach. The code was run on my CPU, but the speed could also be improved by using the GPU.\\

Hyperparameter tuning for the MLPs would be interesting to investigate further with e.g. the more advanced method Bayesian hyperparameter tuning. The article from \parencite{liaw2018tune} looks at how hyperparameter tuning can be easy implemented, which is worth looking at. The data sets could have been bigger or the labels could have been generated with a different method. Another interesting aspect to investigate is to calculate the derivatives of the pricing function, which gives the risks for the derivative books. It looks like MLPs are superior for calculating risks in terms of speed to the classical methods, hence there is potentially an additional gain using deep learning.\\


