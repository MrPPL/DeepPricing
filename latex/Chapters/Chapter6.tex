% Chapter Template

\chapter{Numerical Investigation and Discussion} % Main chapter title

\label{Chapter6} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

This chapter will compare empirically all the numerical methods presented for different types of contingent claims. The first section looks at the closed form solutions to the european options compared with lattice approch for pricing.


%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
\section{European Options}
European options are simple in the sense, that they can only be exercise at maturity. Thoughout the previous chapters specially chapter \ref{Chapter2} and \ref{Chapter3} we have seen closed form solutions for the european call, call on max, call on min and geometric average options. The lattice model presented is a numerical model to approximate european options and american options. The closed form solutions and the numerical lattice approch can be compared for european options, where a small deviation indicates that the lattice approach gives reasonable prices for the american options.\\

First we compare the numerical cost for european put min option by increasing the number of equidistant time-steps, where a trade-off between time and accuracy is investigated. The european put min has a closed form solution\footnote{Equation \eqref{putMin} and \eqref{callMax}}, hence the effect on accuracy is measured by comparision. The computation time is measured in order to discuss the trade-off between speed and accuracy. Tabel \ref{tab:TradeOffEuroMin} shows that the algorithm accuracy increases with the number of equidistant time-steps, but the computational speed dramatically slows down for high number of steps. In MLPs II pricing method we used 100 equidistant time-steps, because we simulated 300.000 datapoints, which is a computational heavy task. We could have chosen more time-steps for a increased accuracy for the true price, but we judged the cost higher in terms of computational time than the benefits. For the other tables will we use BEG with 500 time-steps, because henceforth we need considerable less prices, hence the accuracy weights more.\\

\begin{table}[th]
\caption{Comparision of speed and accuracy for a european put min option, where the inputs are K=40, $S_1(0)=S_2(0)=40$, $\sigma_1=0.2, \sigma_2=0.3$, T=1, $\rho=0.5$  and r=0.06. Note ms is shorthand for millisecond}
\label{tab:TradeOffEuroMin}
\centering
\begin{tabular}{l l l l}
\toprule
\textbf{Method} & \textbf{No. Steps} & \textbf{Price} & \textbf{Time: min:sec.ms} \\
\midrule
BEG & 10 & 4.248 & 0:00.003\\
& 50 & 4.341 & 0:00:097\\
& 100 & 4.352 & 0:00.591\\
& 200 & 4.358 & 0:04.121\\
& 500 & 4.361 & 0:59.337\\
& 1000 & 4.362 & 9:34.164\\
Analytic form & & 4.363 & \\
\bottomrule\\
\end{tabular}
\end{table}

\begin{table}[th]
\caption{Comparision of speed and accuracy for a american put min option, where the inputs are K=40, $S_1(0)=S_2(0)=40$, $\sigma_1=0.2, \sigma_2=0.3$, T=1, $\rho=0.5$  and r=0.06. Note ms is shorthand for millisecond}
\label{tab:TradeOffAmerMin}
\centering
\begin{tabular}{l l l l}
\toprule
\textbf{Method} & \textbf{No. Steps} & \textbf{Price} & \textbf{Time: min:sec.ms} \\
\midrule
BEG & 10 & 4.524 & 00:00.006\\
& 50 & 4.594 & 00:00.250\\
& 100 & 4.602 & 00:01.837\\
& 200 & 4.605 & 00:14.025\\
& 500 & 4.608 & 03:35.039\\
& 1000 & 4.609 & 28:32.584\\
Analytic form & & 4.363 & \\
\bottomrule\\
\end{tabular}
\end{table}

Table \ref{tab:PriceEuropean} shows that the BEG and CRR model have highest accuracy for 100 equidistant time-steps hence we choose to price with N=100 for the multivariate binomial model. The biggest absolute difference is 0.013 which is reasonable within the bid-ask spread for most options.

\begin{table}[th]
\caption{Valuation of multivariate contigent claims with two underlyings with K=40, $S_1(0)=S_2(0)=40$, $\sigma_1=0.2, \sigma_2=0.3$, T=1, $\rho=0.5$  and r=0.06.}
\label{tab:PriceEuropean}
\centering
\begin{tabular}{l l l l}
\toprule
\textbf{Derivative type} & \textbf{Method} & \textbf{No. Steps} & \textbf{Price} \\
\midrule
European Call Minimum & BEG & 100 & 2.475\\
& Analytic form & & 2.483\\
European Call Maximum & BEG & 100 & 7.787\\
& Analytic form & & 7.800\\
Geometric Average Put & BEG & 100 & \\
& Analytic form & & \\
\bottomrule\\
\end{tabular}
\end{table}

\begin{table}[th]
\caption{Valuation of multivariate contigent claims with two underlyings with K=40, $S_1(0)=S_2(0)=40$, $\sigma_1=0.2, \sigma_2=0.3$, T=1, $\rho=0.5$  and r=0.06.}
\label{tab:multidimTree}
\centering
\begin{tabular}{l l l l}
\toprule
\textbf{Derivative type} & \textbf{Method} & \textbf{No. Steps} & \textbf{Price} \\
\midrule
American Put Minimum & BEG & 10 & 3.830\\
 &  & 50 & 3.884\\
 &  & 100 & 3.890\\
\bottomrule\\
\end{tabular}
\end{table}

From table \ref{tab:multidimTree} we see that the BEG approach  The results are promising for valuation of american put options based on several underlying assets. This table will serve as reference and benchmark for the more recent approaches with neural networks in chapter \ref{Chapter6}.


\section{American Put Option}

\section{Exotic American Options}


\section{Numerical Investigation}



The computer is discrete, hence we simulate the stock path as an Bermudan option, where we have 50 time-steps per year. I.e. we approximate the American option with a Bermudan option on same underlying. 
 We simulate 100.000 paths for the stock.
By the above two algorithms for valuation, we choose to vary spot, volatility and maturity for pricing an American put option with K=40 and r=0.06. This table will serve as reference for the machine learning algorithm in chapter (!TODO chapter for machine learning). For the binomial tree we use 100 time-steps, which gives stable results (compare to figure \ref{fig:binConv}) and for the LSM we use $10^5$ paths with 50 time-steps per year. The European option is valued by using BS closed form solution for a call option (see proposition \ref{BS-price-EuroCall}) and Put-call parity (see proposition \ref{Put-call-parity}).
\begin{table}[H]
\caption{Valuation of American put option with K=40 and r=0.06.}
\label{tab:treatments}
\centering
\begin{tabular}{l l l l l l l }
\toprule
\textbf{Spot} & \textbf{$\sigma$} & \textbf{T} & \textbf{Closed form European} & \textbf{Binomial Tree} & \textbf{LSM} & \textbf{abs. diff.} \\
\midrule
36 & 0.2 & 1 & 3.844 & 4.488 & 4.478 & 0.010\\
36 & 0.2 & 2 & 3.763 & 4.846 & 4.828 & 0.018\\
36 & 0.4 & 1 & 6.711 & 7.119 & 7.092 & 0.027\\
36 & 0.4 & 2 & 7.700 & 8.508 & 8.500 & 0.008\\
38 & 0.2 & 1 & 2.852 & 3.260 & 3.245 & 0.015\\
38 & 0.2 & 2 & 2.991 & 3.748 & 3.735 & 0.013\\
38 & 0.4 & 1 & 5.834 & 6.165 & 6.144 & 0.021\\
38 & 0.4 & 2 & 6.979 & 7.689 & 7.665 & 0.024\\
40 & 0.2 & 1 & 2.066 & 2.316 & 2.313 & 0.003\\
40 & 0.2 & 2 & 2.356 & 2.885 & 2.881 & 0.004\\
40 & 0.4 & 1 & 5.060 & 5.310 & 5.326 & 0.016\\
40 & 0.4 & 2 & 6.326 & 6.914 & 6.908 & 0.006\\
42 & 0.2 & 1 & 1.465 & 1.622 & 1.622 & 0.000\\
42 & 0.2 & 2 & 1.841 & 2.217 & 2.212 & 0.005\\
42 & 0.4 & 1 & 4.379 & 4.602 & 4.596 & 0.006\\
42 & 0.4 & 2 & 5.736 & 6.264 & 6.243 & 0.021\\
44 & 0.2 & 1 & 1.017 & 1.117 & 1.113 & 0.004\\
44 & 0.2 & 2 & 1.429 & 1.697 & 1.688 & 0.009\\
44 & 0.4 & 1 & 3.783 & 3.956 & 3.962 & 0.006\\
44 & 0.4 & 2 & 5.202 & 5.656 & 5.649 & 0.007\\
\bottomrule\\
\end{tabular}
\end{table}
We see the maximum difference between the two algorithms is 0.027 at S=38, $\sigma=0.4$ and T=2. The other obvious fact is that the European put has a lower value than its American counterpart, because the continuous exercise feature adds additional value to the put option. 



The continuous time problem for american options is given as a optimal stopping problem:
\begin{align}
\sup_{\tau \in \mathcal{T}([0,T])} E^Q[\exp(-r\tau)g(x_{\tau})]
\end{align}
Where $\tau$ is a stopping time (definition \ref{StoppingTime}), $\mathcal{T}([0,T])$ is the class og all [0,T]-valued stopping times, g(x) is the intrinsic value of the option when the underlying state is x and the risk neutral state process assumed to be markov $\{x_t \in \mathbb{R}^{d} | 0 \leq t \leq T\}$. The continuous problem is often approximated by a discrete version, where the computational procedures can be applied, hence the american option is approximated by a bermuda option. For simplicity we assume that the state process is time-homogeneous and we model a discrete pricing problem. The reformulation of the optimal stopping problem in discrete time is:
\begin{align*}
\sup_{\tau \in \mathcal{T}(0,\ldots,T)} E^Q[\exp(-r\tau)g(x_{\tau})]
\end{align*}
We introduce the value function $J_n(x)$ which is the value of the option at time n if the underlying state process is equal to x
%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------
Universal approximate theorem

The results will vary for each time running the algorithm given the stochastic nature in optimization and in sampling.


To compare the results by 

\begin{table}[th]
\caption{Valuation of American put option with K=40 and r=0.06.}
\label{tab:treatments}
\centering
\begin{tabular}{l l l l l l l }
\toprule
\textbf{Spot} & \textbf{$\sigma$} & \textbf{T} & \textbf{MLPs Regression} & \textbf{Binomial Tree} & \textbf{LSM} & \textbf{abs. diff.} \\
\midrule
36 & 0.2 & 1 & 4.584 & 4.488 & 4.478 & 0.010\\
36 & 0.2 & 2 & 4.649 & 4.846 & 4.828 & 0.018\\
36 & 0.4 & 1 & 7.090 & 7.119 & 7.092 & 0.027\\
36 & 0.4 & 2 & 8.487 & 8.508 & 8.500 & 0.008\\
38 & 0.2 & 1 & 3.094 & 3.260 & 3.245 & 0.015\\
38 & 0.2 & 2 & 3.638 & 3.748 & 3.735 & 0.013\\
38 & 0.4 & 1 & 6.172 & 6.165 & 6.144 & 0.021\\
38 & 0.4 & 2 & 7.605 & 7.689 & 7.665 & 0.024\\
40 & 0.2 & 1 & 2.114 & 2.316 & 2.313 & 0.003\\
40 & 0.2 & 2 & 2.779 & 2.885 & 2.881 & 0.004\\
40 & 0.4 & 1 & 5.274 & 5.310 & 5.326 & 0.016\\
40 & 0.4 & 2 & 6.839 & 6.914 & 6.908 & 0.006\\
42 & 0.2 & 1 & 1.494 & 1.622 & 1.622 & 0.000\\
42 & 0.2 & 2 & 2.167 & 2.217 & 2.212 & 0.005\\
42 & 0.4 & 1 & 4.548 & 4.602 & 4.596 & 0.006\\
42 & 0.4 & 2 & 6.197 & 6.264 & 6.243 & 0.021\\
44 & 0.2 & 1 & 1.000 & 1.117 & 1.113 & 0.004\\
44 & 0.2 & 2 & 1.678 & 1.697 & 1.688 & 0.009\\
44 & 0.4 & 1 & 3.949 & 3.956 & 3.962 & 0.006\\
44 & 0.4 & 2 & 5.649 & 5.656 & 5.649 & 0.007\\
\bottomrule\\
\end{tabular}
\end{table}
\parencite{liaw2018tune}

\section{Black Scholes Model}
In the B-S setup in section \ref{classicBS} we assume constant volatility, which is not realistic in terms of the known fact that volatility skew for equity options (p. 458 \parencite{Hull}).

The underlying risky equity assets is assumed in black scholes theory to evolve with a GBM, where the distribution of possible stock prices at the end of any interval is lognormal. Other models could have been considered e.g. the Bachelor model, where the differences in time for a stock are normal distributed. 
\begin{equation*}
dS_i=\sigma_i dW_i
\end{equation*}
This assumption would simplify the pricing problem of arithmetic basket options, because the problem is essentially one dimensionel like in the case with the geometric basket option for the black scholes model (section \ref{GeoBasket}). A disadvantage with the bachelier model is it can lead to negative stock values, which is not realistic. The Black-Scholes model has some drawbacks where you can question that is the probability distribution of asset prices really lognormal. \\

Empirical real data from markets has not constant volatility, but the volatility depends both on the maturity and strike, hence the investors talks about volatility shew or volatility smiles (chapter 20 \parencite{Hull}). The reason why equity options have shew in the volatility term structure is that investors are more concerned with falling stock prices than rising prices, hence the volatility are instantaneously negative correlated with the stock price. To overcome the issue about assuming constant volatility a model with stochastic variance can be considered. The model becomes more complex with a extra stochastic variable where for simplicity we consider the two factor Heston model. The basic model is given by the stock follow the SDE:
$$dS(t)=\alpha S(t) dt + \sqrt{V(t)} S(t) dW_S(t)$$
And the stochastic variance process $V(t)$ is the solution to the SDE:
$$dV(t)=a(\theta - V(t))dt + \epsilon \sqrt{V(t)} dW_V(t) \quad where a>0,\theta>0, \epsilon>0 \ and \ V(0)>0$$
Where $W_S(t)$ and $W_V(t)$ have correlation $\rho$. The interpretation of the constants are $\theta$ is long run average price variance, a is the rate which $V(t)$ reverts to $\theta$ and $\epsilon$ is the volatility of the volatility. The implication of $\epsilon$ is that $V(t)$ is more volatile when volatility is high and correlation between the stock and variance process reveals the negative correlation. The negative correlation between the two processes display the real market phenomenon of volatility shew for equity options, hence by assuming stochastic volatility the Heston model overcomes the issue with volatility shew.\\

Other models for describing the stochastic underlying process could be "Constant Elasticity of Variance model", "Merton's Mixed Jump-Diffusion Model", "Variance-Gamma Model"

Another underlying would could be the heston model

pay transaction costs and taxe

Options can be interpreted as corporate securities

credit risk and Mertons model

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Neural Networks Vs. Linear Model}
Remember that neural network does not have curse of dimensionality, hence the method compared to the linear model has advantages when considering multivariate contingent claims.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\subsection{Subsection 2}
Computational time scales exponentially for PDE methods with the number of underlyings and the same goes for the binomial lattice approach, because both methods use dynamic programming. For the monte carlo methods the computational time only scales linear with the number of underlyings, where a smart method is needed for calculating stopping times.

Pricing options with early exercise decisions is not a issue with backward pricing methods.

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Main Section 2}
\parencite{liaw2018tune}
\parencite{FergusonRyan2018}

Methods cannot be compared due to lack of code efficientcy. This is something that can be optimized. 