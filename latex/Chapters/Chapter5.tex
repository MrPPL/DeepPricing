% Chapter Template

\chapter{Option Pricing And Deep Learning} % Main chapter title

\label{Chapter5} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

Deep learning can be applied to option valuation in different ways. The first method is to simulate input parameter, i.e. the market parameters and model parameters and then using a classical method for calculating target values $\bm{y}$ for the given input parameters $\matr{X}$. The method falls within supervised regression where we will use a MLPs network introduced in section \ref{multilayerPerceptron} to approximate the mapping. We will assume for simplicity the stock follow a GBM, hence from earlier chapters the generations of labels for european and american stock options are already presented (Chapter \ref{Chapter2}, \ref{Chapter3}). The theory in chapter \ref{Chapter4} will be specialized for the specific task and discussed. The supervised MLPs regression will be used to valuate european call options and american put options. The advantage of MLPs is the model can easily be extendend to high dimensional data, where the classical method polynomial regression (section \ref{LSM}) is prone to overfit and slow compared to MLPs. 

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Multilayer Perceptrons Regression For European Options}
For the european option with have a analytical solution to the option pricing problem, hence we can easily produce the data set with input features and target variable $(\matr{X},\bm{y})$. The section is inspired by \parencite{HirsaAli2019}. In the performance section we will look at how the MLPs performs compared to standard polynomial regression.

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Data}
Remember the 5 parameters for pricing an european call option (proposition \ref{BS-price-EuroCall}).  The european call option is a linear homogeneous function in $(S_0,K)$, hence the valuation formula can be modified:
$$\frac{c(S_0,K)}{K}=c(\frac{S_0}{K},1)$$
The alternative representation reduced the number of parameters needed for simulation, where instead of both $S$ and $K$, moneyness ($\frac{S_0}{K}$) is simulated. The inputs $\matr{X})$ will be varying combinations of the 4 parameters and the target variable will be generated by the Black-Scholes for a european call option. The parameters ranges for training is given in table \ref{tab:euroParRange}, where the maturity ranges for one day to 3 years (assuming 252 trading days). 

\begin{table}[th]
\caption{Parameter range}
\label{tab:euroParRange}
\centering
\begin{tabular}{l l l l l l }
\toprule
\textbf{Moneyness} & \textbf{r} & \textbf{$\sigma$} & \textbf{T} \\
\midrule
0.8-1.2 & 1\%-3\% & 0.05-0.5 & 1/252-3.0\\ 
\bottomrule\\
\end{tabular}
\end{table}

In the above ranges we both simulated a training and test data set, where the total number of simulations where split 80-20 to the respective data sets. To generate data quasi-random sequence method is applied to obtain low discrepancy. We used Halton sequences instead of uniform sampling, because the Halton sequence covers the space more evenly quicker. Like uniform sampling the halton sequence points is between 0 and 1, hence we need to apply a transformation to get the parameter ranges:
$$r \cdot (range \ of \ parameter) + lowerBound \quad where \ r=halton \ point$$
After the four inputs features were simulated, we found the corresponding target value y with BS-formula. 

\begin{figure}[th]
\centering
\includegraphics{Figures/marginalEuroCall.png}
\decoRule
\caption[Marginal distributions for european call]{Quasi random simulation with halton sequence}
\label{fig:marginalEuro}
\end{figure}

The marginal distributions (see figure \ref{fig:marginalEuro}) shows that we have succesfully generated parameters in the given ranges and the parameters are evenly spaced in the ranges. The target y has a right shewed marginal distribution. We sampled 240.000 training samples and 60.000 test samples, where the marginal distributions is showed for the training samples.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\subsection{Training}
The MLPs is to infer Black-Scholes formula out from the generated data, the model does not know anything about Black-Scholes. The cost function chosen is the empirical risk function with a quadratic loss function, i.e. mean square error (MSE):
$$J(\theta)= \frac{1}{n} \sum_{i=1}^{n}(y_i-\hat{y}_i)^2$$
The choice is stardard for regression. The optimization algorithm chosen is Adam, where the learning rate is set to $\eta=0.001$. The architecture of the network is 4 layers, 120 neurons in each hidden layer and 1 output. In each layer we choose the activation function leaky ReLU, where in hyperparameter tuning, we will try with elu in each layer instead.

\subsubsection{Hyperparameter Tuning}
The hyperparameter chosen is based on \parencite{HirsaAli2019}, nevertheless we will try with elu. ELU has linear asymptotes, which is the desired behaviour in valuation problems: financial products are often linearly extrapolated and this behaviour is often enforced. For example, in finite difference methods, we generally work with linear boundary conditions. ELU is also considered a best practice presently in the deep learning community, for very different reasons related to speed and stability of numerical optimization.


%-----------------------------------
%	SUBSECTION 3
%-----------------------------------
\subsection{Model Performance}
The model performance is evaluated by MSE, RMSE, MAE and coefficient of determination, where all the measures evaluate how close is the model predictions with the actual targets. For a high quality model the first three measures should be close to 0, where the latter should be close to 1. For MSE close to 0 means that the model predictions does not differ a lot from the observed targets. The RMSE and MAE are same kind of measure, but just measured slightly different. The RMSE is the square root of MSE, which means MSE and RMSE penalize large errors. The MAE is the mean absolute error and large errors is penalized less. Coefficient of determination provides a measure of how well observed targets are replicated by the model, based on the proportion of total variation of target explained by the model.

\begin{table}[th]
\caption{Prediction results for european call test data for in sample}
\label{tab:euroParRange}
\centering
\begin{tabular}{l l l l l l }
\toprule
\textbf{MSE} & \textbf{RMSE} & \textbf{MAE} & \textbf{Coefficent of Determination} \\
\midrule
0.000006 & 0.002419 & 0.0019661242 & 0.99942\\
\bottomrule\\
\end{tabular}
\end{table}

The performance measures are generally good, we see MAE, MSE and RMSE all have values less than 0.002419 from zero and a coefficient of determination 0.00058 from 1. 

\begin{figure}[th]
\centering
\includegraphics{Figures/PredictionEuroC.png}
\decoRule
\caption[MLPs Predictions Vs. Actual Prices]{Predicted price based on MLPs model}
\label{fig:MLPsEuroC}
\end{figure}

Illustration of the model fit is also provided, where the plot shows $\frac{c(S_0,K)}{K}$ predicted from the model and observed target values. The conclusion from the performance metrics is also present in the figure, where we see the model predicts close to target values over the whole range. Before moving on to pricing for american options, we investigate if polynomial regression can perform as MLPs

\subsection{Polynomial Regression}
The dataset in the MLPs regression is the same for the polynomial regression, further we choose same performance metrics, but the model and model training is obvously different from the MLPs. There is exists now a closed form solution for the optimation problem by solving the "normal equations" and we have a linear model. We fit polynomials up to degree 6 for comparision of the model capacity and fit. From the illustration (figure \ref{fig:PolynomialEuroC}) is it clear, that the fit improves with increased model capacity. The linear regression is too simple for pricing european option, but it looks like the 6 order polynomial actually performs better than the MLPs in the in-sample test set (see also table \ref{tab:euroPerformance})
\begin{figure}[H]
\centering
\includegraphics{Figures/polynomialEuroC.png}
\decoRule
\caption[Polynomial Regression Predictions Vs. Actual Prices]{Predicted price based on polynomial regression of varying degree}
\label{fig:PolynomialEuroC}
\end{figure}

The table is created to compare the performance for each model. The table confirms that the linear regression has a worse fit than the other models with higher capacity. The difference on the MLPs and higher order polynomial regression models less than $6\cdot 10^{-4}$ for coefficient of determination and less than $15 \cdot 10^{-3}$. The difference is negible so the fit for MLPs and polynomail regression of degree 4-6 performs all very well on the data.

\begin{table}[th]
\caption{Prediction results for european call test data for in sample polynomial regression}
\label{tab:euroPerformance}
\centering
\begin{tabular}{l l l l l l l l }
\toprule
\textbf{Model} & \textbf{Dataset} & \textbf{MSE} & \textbf{RMSE} & \textbf{MAE} & \textbf{$R^2$} \\
\midrule
Linear Reg. & Test & 0.000631 & 0.025117 & 0.018265 & 0.937468\\
2. degree & Test & 6.88e-05 & 0.008292 & 0.006133 & 0.993185\\
3. degree & Test & 1.31e-05 & 0.00362470 & 0.002559 & 0.998698\\
4. degree &Test & 4.25e-06 & 0.002062 & 0.001283 & 0.999578\\
5. degree & Test & 1.99e-06 & 0.001411 & 0.000865 & 0.999803\\
6. degree & Test & 9.23e-07 & 0.000961 & 0.000592 & 0.999908\\
MLPs & Training & 0.000006 & 0.002419 & 0.001966 & 0.99942\\
MLPs & Test & 0.000006 & 0.002419 & 0.001966 & 0.99942\\
\bottomrule\\
\end{tabular}
\end{table}

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------
\section{Multilayer Perceptrons Regression For American Options}

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Data}

\begin{figure}[th]
\centering
\includegraphics{Figures/marginalAmerPut.png}
\decoRule
\caption[Marginal distributions for american put]{Quasi random simulation with halton sequence}
\label{fig:marginalEuro}
\end{figure}

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
\subsection{Optimization and cost function}

%-----------------------------------
%	SUBSECTION 3
%-----------------------------------
\subsection{Model Performance}

%------------------------------------------

%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------
\section{Multilayer Perceptrons Regression For European Basket Call Max}

\parencite{FergusonRyan2018}